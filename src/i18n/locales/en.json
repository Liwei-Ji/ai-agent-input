{
  "ui": {
    "lang_en": "English",
    "lang_zh": "繁體中文",
    "lang_ja": "日本語",
    "back": "Back"
  },

  "detail": {
    "default_paragraph_1": "This design pattern guides users to interact more effectively with AI by providing intuitive interface feedback."
  },

  "Wayfinders": "Wayfinders",
  "Give users clues about how to interact with the model, particularly when getting started.": "Give users clues about how to interact with the model, particularly when getting started.",
  
  "Follow up": "Follow up",
  "Get more information from the user when the initial prompt isn't sufficiently clear": "Get more information from the user when the initial prompt isn't sufficiently clear",
  "follow_up.desc_1": "In an ideal scenario, the user is so good at prompting that they can reach a great outcome on their first try. In reality, that's often not the case. Follow ups are prompts, questions, or inline actions that help users refine or extend their initial interaction with the model so the model can better understand their intent.",
  "follow_up.desc_2": "A well-timed follow up saves compute cycles, prevents wasted effort, and communicates that the AI is working alongside the user rather than starting over.",

  "Initial CTA": "Initial CTA",
  "Large, open-ended input inviting the user to start their first interaction with the AI": "Large, open-ended input inviting the user to start their first interaction with the AI",
  "initial_cta.desc_1": "For many products, the first touchpoint with AI is through the Initial CTA: A prominent collection of inputs and actions that allow a user to start prompting. From here, the user works with the model through regenerations, variants, and other actions in order to reach their intended goal.",
  "initial_cta.desc_2": "The most common implementation of this pattern is a large direct input box, where the system goal is to understand the user’s context and intent as quickly as possible while minimizing the amount of work they have to do to express it. The implementation of this pattern varies depending on the context and capabilities of the surrounding application.",

  "Nudges": "Nudges",
  "Alert users to actions they can take to use AI, especially if they are just getting started": "Alert users to actions they can take to use AI, especially if they are just getting started",
  "nudges_cta.desc_1": "What happens when a tool is capable of performing many tasks, but users are only aware of a small subset of its functions?",
  "nudges_cta.desc_2": "Nudging is a gentle guidance mechanism that helps users initiate actions by gradually revealing the capabilities of artificial intelligence, combined with actionable trigger prompts.",
  
  "Suggestions": "Suggestions",
  "Solves the blank canvas dilemma with clues for how to prompt": "Solves the blank canvas dilemma with clues for how to prompt",
   "suggestions_cta.desc_1":"Artificial intelligence can only deliver its maximum value once it has information about you. When a new topic is initiated for the first time, the system’s understanding of the user is still limited.",
   "suggestions_cta.desc_2":"Recommendation features can help the system acquire some initial information about users.",
  
  "Templates": "Templates",
  "Structured templates that can be filled by the user or pre-filled by the AI": "Structured templates that can be filled by the user or pre-filled by the AI",
  "templates_cta.desc_1":"Templates reduce the learning curve of complex products by allowing new users to get started quickly and complete tasks within familiar structures.",
  "templates_cta.desc_2":"The strength of templates lies in their ability to unify parameters, recommended prompts, and text inputs into a single experience, making them especially well suited for tools that require highly specific prompts to produce consistent results.",

  "Inputs": "Inputs",
  "Submit the user's prompt to the AI within its surrounding context": "Submit the user's prompt to the AI within its surrounding context",
  
  "Auto fill": "Auto fill",
  "Makes it easy for users to extend a prompt to multiple inputs at once": "Makes it easy for users to extend a prompt to multiple inputs at once",
  "auto_fill_cta.desc_1":"Autofill leverages users’ explicit or implicit intent to complete prompts and actions across multiple fields or records in a single step, making it particularly suitable for repetitive tasks or inputs with predictable formats.",
  "auto_fill_cta.desc_2":"As users enter information, the system provides real-time, context-aware predictions, extracting key details from the text and populating structured fields or variables—such as automatically completing forms, updating workflow parameters, or pre-filling systems like CRMs.",

  "Inline Action": "Inline Action",
  "Ask or interact with AI contextually based on something already available on the page": "Ask or interact with AI contextually based on something already available on the page",
  "inline_action_cta.desc_1":"Users do not always need to regenerate an entire piece of content; they often want to modify or respond to just a small section. Inline actions allow adjustments to occur directly at the specified location.",
  "inline_action_cta.desc_2":"When text is selected and highlighted, the interface displays an inline action panel, guiding the AI to focus on the region the user intends to edit.",

  "Quote Reply": "Quote Reply",
  "Enable users to initiate a contextual AI query directly from selected content, preserving focus and reducing disruption to the primary interaction flow.":"Enable users to initiate a contextual AI query directly from selected content, preserving focus and reducing disruption to the primary interaction flow.",
  "quote_reply_cta.desc_1":"Through citations, users can trace the sources underlying AI responses, linking outputs to relevant materials such as PDFs, transcripts, web pages, or internal databases. Citations increase transparency and enable users to verify information.",
  "quote_reply_cta.desc_2":"Citations also help build user trust, making summaries appear more reliable. However, if a summary contains errors or distortions, citations may inadvertently contribute to misinformation.",

  "Madlibs": "Madlibs",
  "Repeatedly run generative tasks without compromising on the format or accuracy": "Repeatedly run generative tasks without compromising on the format or accuracy",
  "mablibs_cta.desc_1":"",
  "mablibs_cta.desc_2":"",

  "Open text": "Open text",
  "Open ended prompt inputs that can be used in AI conversations and other natural language prompting": "Open ended prompt inputs that can be used in AI conversations and other natural language prompting",
  "open_text_cta.desc_1":"",
  "open_texe_cta.desc_2":"",

  "Remix": "Remix",
  "Use existing content as the starting point for prompting": "Use existing content as the starting point for prompting",
  "remix_cta.desc_1":"",
  "remix_cta.desc_2":"",

  "Restyle": "Restyle",
  "Transfer styles without changing the underlying structure of a generation": "Transfer styles without changing the underlying structure of a generation",
  "restyle_cta.desc_1":"",
  "restyle_cta.desc_2":"",

  "Summary": "Summary",
  "Have AI distill a topic or resource down to its essence": "Have AI distill a topic or resource down to its essence",
  "summary_cta.desc_1":"",
  "summary_cta.desc_2":"",

  "Synthesis": "Synthesis",
  "Distill or reorganize complicated information into simple structure": "Distill or reorganize complicated information into simple structure",
  "synthesis_cta.desc_1":"",
  "synthesis_cta.desc_2":"",

  "Token layering": "Token layering",
  "Construct a prompt with raw tokens, just like building with legos": "Construct a prompt with raw tokens, just like building with legos",
  "token_layering_cta.desc_1":"",
  "token_layering_cta.desc_2":"",

  "Transform": "Transform",
  "Use AI to change the modality of content": "Use AI to change the modality of content",
  "transform_cta.desc_1":"",
  "transform_cta.desc_2":"",

  "Tuners": "Tuners",
  "Let users refine or remix their prompt to get improved results": "Let users refine or remix their prompt to get improved results",
  
  "Collapse Input":"Collapse Input",
  "Improve focus and layout efficiency by collapsing the input area while preserving all input content.":"Improve focus and layout efficiency by collapsing the input area while preserving all input content.",
  "collapse_input_cta.desc_1":"",
  "collapse_input_cta.desc_2":"",

  "Attachments": "Attachments",
  "Give the AI a specific reference to anchor its response": "Give the AI a specific reference to anchor its response",
  "attachments_cta.desc_1":"",
  "attachments_cta.desc_2":"",

  "Filters": "Filters",
  "Constrain the inputs or the outputs of the AI by source, type, modality, etc": "Constrain the inputs or the outputs of the AI by source, type, modality, etc",
  "filters_cta.desc_1":"",
  "filters_cta.desc_2":"",

  "Inpainting": "Inpainting",
  "Target specific areas of the AI's result to regenerate or remix": "Target specific areas of the AI's result to regenerate or remix",
  "inpainting_cta.desc_1":"Interfaces should help users quickly identify editable regions and provide precise interaction methods that allow them to select the exact scope of changes. Applying inline actions directly to highlighted text can significantly improve editing efficiency.",
  "inpainting_cta.desc_2":"The ability to make localized adjustments allows users to ask the AI to modify specific sections without regenerating the entire content, making collaboration more stable and controllable while reducing rework costs and increasing iteration speed.",

  "Model management": "Model management",
  "Let users specify what model to use for their prompts": "Let users specify what model to use for their prompts",
  "model_management_cta.desc_1":"For reasons of performance, quality, or cost, users may wish to switch the model used for generating outputs. Different models have distinct strengths and limitations, so providing a model-switching feature—or clearly displaying the currently active model—has become a standard practice in AI products.",
  "model_management_cta.desc_2":"Model options are typically presented in a hierarchical manner, with each tier representing different trade-offs and suitable use cases.",

  "Parameters": "Parameters",
  "Include constraints with your prompt for the AI to reference when generating its result": "Include constraints with your prompt for the AI to reference when generating its result",
  "parameters_cta.desc_1":"Parameters act as regulators between user intent and the model’s generation process, helping the AI interpret inputs, weigh trade-offs, and form responses. They function like dials on a machine, allowing users to control the AI’s level of strictness, exploration, constraint, and proactiveness.",
  "parameters_cta.desc_2":"Default values should be designed to be clear and easy to understand. Since most users will not adjust parameters, defaults should prioritize common and intuitive options, avoiding confusion for new users while still offering advanced settings when needed.",

  "Personal voice": "Personal voice",
  "Ensure outputs match your voice, tone, and preferences in a consistent way": "Ensure outputs match your voice, tone, and preferences in a consistent way",
  "personal_voice_cta.desc_1":"Adjusting tone should not require a complex configuration process. By offering real-time, lightweight tone-switching options during text generation, users can quickly change the tone without rewriting the prompt and clearly see which tone is currently active.",
  "personal_voice_cta.desc_2":"Distinguishing between different tones and roles is essential. Users are generally less concerned with the AI’s personality settings themselves and more focused on whether the responses fit the usage context.",

  "References": "References",
  "See and manage what additional sources the AI references to generate its response": "See and manage what additional sources the AI references to generate its response",
  "references_cta.desc_1":"Sources refer to external content that the AI retrieves and cites while generating responses, connecting the model’s existing knowledge with the user’s current context to ensure outputs are grounded in verifiable evidence. This design relies heavily on Retrieval-Augmented Generation (RAG) architectures, which integrate internal model knowledge with real-time external data, rather than relying solely on training data and prompt context.",
  "references_cta.desc_2":"Presenting summaries together with clear source information helps users understand where information comes from, assess its credibility, and constrain the scope of the AI’s reasoning. Without source attribution, systems are easily perceived as unverifiable black boxes; in contrast, clearly identified sources allow users to filter, relate, and click through to verify information, giving them greater control over the results.",

  "Workflows": "Workflows",
  "String generative steps together to synthesize, create, or send content on auto-pilot": "String generative steps together to synthesize, create, or send content on auto-pilot",
  "workflows_cta.desc_1":"Workflows combine multiple steps into repeatable and predictable sequences of actions. As agent capabilities expand, interaction models are shifting toward supporting agents that generate and explain their own workflows, making their behavior understandable and open to inspection. As a result, interfaces must not only support workflow construction but also serve review and audit functions.",
  "workflows_cta.desc_2":"Unlike dynamically stitched prompt chains, workflows are defined in advance and executed repeatedly using fixed instructions and parameters, ensuring consistent outcomes. This consistency makes them particularly well suited for teams that need to maintain quality and reliability across repetitive tasks.",

  "Governors": "Governors",
  "Maintain user agency as the AI works in order to understand and direct the AI's logic": "Maintain user agency as the AI works in order to understand and direct the AI's logic",
  
  "Citations": "Citations",
  "Give the AI a specific reference to anchor its response": "Give the AI a specific reference to anchor its response",
  "citations_desc_1":"Through citations, users can trace the data sources underlying AI responses, linking outputs back to original materials such as PDFs, transcripts, web pages, or internal documents. This improves transparency and supports verification.",
  "citations_desc_2":"Citations can strengthen users’ perception of the AI’s expertise and authority, increasing the credibility of summaries; however, if a summary contains errors or distortions, citations may instead amplify the risks associated with hallucinations.",

  "Controls": "Controls",
  "Manage the flow of information or pause a request mid-stream to adjust the prompt": "Manage the flow of information or pause a request mid-stream to adjust the prompt",
  "controls_desc_1":"Due to the high cost of computation time, waiting for a process to fully complete before making corrections is both time-consuming and expensive. Control mechanisms allow users to interrupt AI behavior in real time, helping them maintain control over the workflow.",
  "controls_desc_2":"Common control elements include stop icons or cancel buttons, which enable users to terminate a request while generation is in progress. This interrupts all ongoing progress and results in the current work not being saved.",

  "Footprints": "Footprints",
  "Let users trace the AI's steps from prompt to result": "Let users trace the AI's steps from prompt to result",
  "footprints_desc_1":"Provenance trails record how and where artificial intelligence participates in creation, editing, and decision-making. Through multi-layered representations, they help explain how outcomes are formed, support internal review, and meet policy and regulatory requirements.",
  "footprints_desc_2":"Without such records, users cannot assess reliability, reproduce results, or establish accountability. Robust tracking mechanisms enable source verification, decision-path inspection, and reduce the risk of AI misuse or content laundering.",

  "Plan of Action": "Plan of Action",
  "Have the AI show the steps it will take to respond to the user's prompt before it executes its response": "Have the AI show the steps it will take to respond to the user's prompt before it executes its response",
  "plan_of_action_desc_1":"Preview functionality allows users to confirm that a plan is correct before the system executes it, preventing wasted resources and hidden errors.",
  "plan_of_action_desc_2":"Plans should be concise and easy to understand, enabling users to quickly grasp their intent. Overly long or technical plans may reduce readability. For technical or sensitive workflows, it is recommended to allow users to expand steps or interact with the AI to explore the details more deeply.",

  "Stream Of Thought": "Stream Of Thought",
  "Reveals the AI's logic thought process, tool use, and decisions for oversight and auditability" : "Reveals the AI's logic thought process, tool use, and decisions for oversight and auditability",
  "stream_Of_thought_desc_1":"The AI’s thought-flow visualization shows the complete path from user input to final response, including planned steps, tools invoked, executed code, and checks or decisions made along the way. When this information is visible, the system becomes more transparent and helps users build trust.",
  "stream_Of_thought_desc_2":"Beyond deciding what content to display, designers must also consider: how much information to show for each tool call or reference, how to present changes in the AI’s logical state, and the level of detail to include in each summary.",

  "Prompt transparency": "Prompt transparency",
  "Show users what is actually happening behind the scenes": "Show users what is actually happening behind the scenes",
  "prompt_transparency_desc_1":"Users want to understand the reasoning behind AI responses to build trust. The system provides a subtle toggle, keeping the core content clean and uncluttered while avoiding information overload.",
  "prompt_transparency_desc_2":"When the “Prompt Engineering Context” is enabled, users can view the underlying logic, trace the model’s thought process, and analyze the basis for its generated output.",

  "Regenerate": "Regenerate",
  "Have the AI reproduce its response to the prompt without additional input": "Have the AI reproduce its response to the prompt without additional input",
  "regenerate_desc_1":"If the initial AI output is unsatisfactory, users can request the system to regenerate content using the same prompt and context.",
  "regenerate_desc_2":"Common action labels include “Regenerate,” “Try Again,” or “Rerun.” This means that even without changing the prompt, the new response may present different wording, reasoning approaches, or details.",

  "Copy": "Copy",
  "Instantly copy the response to your clipboard.":"Instantly copy the response to your clipboard.",
  "copy_desc_1":"Users often need to quickly integrate AI outputs into other workflows. Providing consistent and clear copy functionality reduces operational friction and prevents errors caused by manual selection.",
  "copy_desc_2":"Each AI message includes a one-click copy feature. When clicked, the full content is automatically copied to the clipboard, with real-time feedback confirming the action has been completed.",

  "Sample response": "Sample response",
  "Confirm the user's intent for complicated prompts": "Confirm the user's intent for complicated prompts",
  "sample_response_desc_1":"Sample responses act as lightweight previews shown before the full output is generated, helping users quickly understand the AI’s intended direction and avoid consuming resources or overwriting content before that direction is confirmed.",
  "sample_response_desc_2":"This mechanism allows users to regain control over the pacing of the workflow. Instead of immediately processing long drafts or running high-cost computations, users can first review a brief proof of concept to validate the direction; if deviations are detected, adjustments can be made immediately, and execution can continue once the direction is confirmed.",

  "Token Transparency": "Token Transparency",
  "Reveal the tokens the AI used to craft its response": "Reveal the tokens the AI used to craft its response",
  "token_transparency_desc_1":"To reduce the uncertainty caused by the black-box nature of generative systems, visualize the token structure and probability information involved in the model’s generation process, allowing users to see how responses are decomposed and assembled.",
  "token_transparency_desc_2":"Provide advanced view options that break text down to the token level and reveal metadata such as token counts, generation latency, and log probabilities, supporting user analysis, debugging, and credibility assessment.",

  "Variations": "Variations",
  "Trace through multiple variations of a result to choose the one that works best for them": "Trace through multiple variations of a result to choose the one that works best for them",
  "variations_desc_1":"Generative AI is inherently probabilistic, meaning outputs may vary randomly. Providing multiple variants allows users to compare different permutations of the model’s responses to the same prompt.",
  "variations_desc_2":"A single seed can generate multiple candidate options, from which users can select. The chosen content is then automatically merged into the main output.",

  "Trust builder": "Trust builder",
  "Give users confidence that the AI's results are ethical, accurate, and trustworthy": "Give users confidence that the AI's results are ethical, accurate, and trustworthy",
  
  "Consent": "Consent",
  "Only capture data from others with their knowledge and permission": "Only capture data from others with their knowledge and permission",
  "consent_desc_1":"Actively obtaining user consent before sharing data with AI helps build trust, provides accountability, and supports an ethically responsible user experience.",
  "consent_desc_2":"Default settings should follow an opt-in rather than opt-out approach, as silence does not equal consent. Even in products with prior authorization, consent should still be obtained before any textual interactions. An opt-in process not only respects user autonomy but also simplifies compliance with emerging AI and privacy regulations.",

  "Watermark": "Watermark",
  "Identifiers on AI Generative content that humans, software, or programs can read": "Identifiers on AI Generative content that humans, software, or programs can read",
  "watermark_desc_1":"Watermark information should be placed where users naturally expect to find it, such as in a “Content Information” panel, metadata view, or on hover. Consistency enhances recognizability and reduces users’ cognitive load.",
  "watermark_desc_2":"Visible labels help prevent misuse and clearly indicate the source, while invisible trackers—such as embedded hashes or model fingerprints—provide tracing and forensic capabilities. Using both in combination enables more comprehensive protection throughout the content lifecycle.",

  "Memory": "Memory",
  "Control what details the AI knows about you": "Control what details the AI knows about you",
  "memory_desc_1":"Memory functionality gives AI systems the ability to retain information across multiple interactions, allowing users to enjoy a coherent and continuous experience without having to provide background information each time. This transforms AI from a mere transactional tool into a reliable long-term assistant.",
  "memory_desc_2":"Newly stored memories should be clearly presented to users, along with simple management options that allow them to control which memories are retained. Users should be able to describe their identity in natural language, and the AI’s understanding of humans should maintain a natural and intuitive interactive feel.",

  "Interact with the AI without leaving any traces": "Interact with the AI without leaving any traces",
  "interact_with_the_ai_without_leaving_any_traces_desc_1":"",
  "interact_with_the_ai_without_leaving_any_traces_desc_2":"",

  "Dark matter": "Dark matter",
  "Potentially nefarious, but certainly ambiguous patterns that impact user trust with questionable user value": "Potentially nefarious, but certainly ambiguous patterns that impact user trust with questionable user value",
  
  "Caveat": "Caveat",
  "Inform users about shortcomings or risks in the model or the technology overall": "Inform users about shortcomings or risks in the model or the technology overall",
  "caveat_desc_1":"AI systems may contain errors, incomplete information, or biases. While this usage pattern is quite common, its effectiveness in helping users develop skepticism and critical thinking still requires further validation.",
  "caveat_desc_2":"For users who are less technically familiar, these prompts provide a simple and direct way to highlight the product’s limitations. Warnings should be positioned close to the results so that users can see them immediately when making decisions.",

  "Rating": "Rating",
  "Signal expectation gaps or errors in the model – but is that clear to the user?": "Signal expectation gaps or errors in the model – but is that clear to the user?",
  "rating_desc_1":"Users should clearly know when they are interacting with an AI model. Through likes or click based feedback, users can inform engineers whether the model’s behavior meets expectations a practice that is especially important for proprietary models or safety focused models handling sensitive data.",
  "rating_desc_2":"In practice, such feedback is often presented using thumbs-up icons or star ratings. Ideally or at least preferably systems should provide more information about what happens after a user submits feedback, transparently indicating whether the evaluation applies to a single response or reflects the overall performance of the model.",

  "Data ownership": "Data ownership",
  "Control how the model remembers and uses your data": "Control how the model remembers and uses your data",
  "data_ownership_desc_1":"The use of personal data online has always been contentious. When people interact with AI or engage in collaborative creation, the boundaries between user data, platform data, and intermediary information often become blurred.",
  "data_ownership_desc_2":"Interfaces should provide transparent and controllable settings, allowing users to clearly understand which features they have enabled or disabled and how their information is being used.",

  "Identifiers": "Identifiers",
  "Differentiate the AI from other features and highlight its use case": "Differentiate the AI from other features and highlight its use case",
  
  "Color": "Color",
  "Visual cues to help users identify AI features or content": "Visual cues to help users identify AI features or content",
  "color_desc_1":"Use color as a supporting cue, allowing it to function as a visual marker that distinguishes AI generated content from human-created content.",
  "color_desc_2":"Visually represent both what data the AI used and where the content originated. Drawing inspiration from how humans use highlighters to mark key points, highlight the core ideas that are being referenced, and clearly list the corresponding references or search results beneath the text, enabling users to click through and verify the information.",

  "Disclosure": "Disclosure",
  "Clearly mark content and interactions guided or delivered by AI": "Clearly mark content and interactions guided or delivered by AI",
  "disclosure_desc_1": "One key way to enhance users’ sense of safety is to remain transparent and explicit throughout their interactions with artificial intelligence.",
  "disclosure_desc_2":  "At the core of disclosure is transparency: when the AI proactively performs actions such as classification, labeling, or archiving, it must clearly indicate that these actions are carried out by the AI, while reserving final decision-making authority for the user.",

  "Name": "Name",
  "How do we refer to the AI?": "How do we refer to the AI?",
  "name_desc_1":"Users have the right to know what or whom they are interacting with.",
  "name_desc_2":"Naming helps set expectations by signaling whether the AI is a tool, a collaborator, or something in between. It also enables customization names can be defined by the company, chosen by the user, or adapted to specific contexts. Through naming, artificial intelligence becomes less of an abstract system and more of a recognizable part of the user’s world.",

  "Personality": "Personality",
  "Characteristics that distinguish the AI's personality and vibe": "Characteristics that distinguish the AI's personality and vibe",
  "personality_desc_1":"A friendly and enthusiastic personality helps create a sense of comfort and encourages users to explore more features; in contrast, a concise and rational personality emphasizes stability and efficiency.",
  "personality_desc_2":"A well-designed personality framework allows a product to share the same core model across diverse contexts, while switching between friendly, professional, or mechanical expression styles simply by adjusting tone, level of formality, and interaction behaviors."
}